{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ea4251-3083-4809-b476-1b360250fa24",
   "metadata": {},
   "source": [
    "# Import The Packages that We Will Use It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f03466-a22c-4166-93e3-65b701b53d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 11:13:41.630032: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 11:13:42.764650: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import register_keras_serializable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25baba84-64a6-4ce2-9ba9-50d5d9621167",
   "metadata": {},
   "source": [
    "**Define Some Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c52f399-6369-40ec-9e5c-9de6c7ba855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Parameters\n",
    "frame_length = 256\n",
    "frame_step = 160\n",
    "fft_length = 384\n",
    "characters = ' ءآأؤإئابتثجحخدذرزسشصضطظعغفقكلمنهةوىي'\n",
    "\n",
    "# Directory containing test audio files\n",
    "test_audio_dir = './Data'\n",
    "output_csv_path = './Output/predictions.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e891adae-c30e-4dac-bcd2-d23fa3f799d5",
   "metadata": {},
   "source": [
    "**Define Some Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e825aa9-ed61-438e-93c0-a1c9f7cd401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String lookup layers\n",
    "char_to_num = keras.layers.StringLookup(vocabulary=list(characters), oov_token=\"\")\n",
    "num_to_char = keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "\n",
    "def preprocess_audio(wav_file):\n",
    "    \"\"\"\n",
    "    Preprocesses a single audio file for ASR.\n",
    "    \n",
    "    Parameters:\n",
    "    - wav_file (str): Path to the audio file (WAV format).\n",
    "    \n",
    "    Returns:\n",
    "    - spectrogram (Tensor): Preprocessed spectrogram.\n",
    "    \"\"\"\n",
    "    file = tf.io.read_file(wav_file)\n",
    "    audio, _ = tf.audio.decode_wav(file)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    \n",
    "    if tf.shape(audio)[0] < fft_length:\n",
    "        pad_amount = fft_length - tf.shape(audio)[0]\n",
    "        audio = tf.pad(audio, paddings=[[0, pad_amount]])\n",
    "    \n",
    "    spectrogram = tf.signal.stft(\n",
    "        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n",
    "    )\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
    "    \n",
    "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
    "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
    "    \n",
    "    return spectrogram\n",
    "\n",
    "def decode_batch_predictions(pred):\n",
    "    \"\"\"\n",
    "    Decodes batch predictions into text using character lookup.\n",
    "    \n",
    "    Parameters:\n",
    "    - pred (Tensor): Predicted output from the model.\n",
    "    \n",
    "    Returns:\n",
    "    - output_text (list): List of decoded text predictions.\n",
    "    \"\"\"\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
    "    output_text = []\n",
    "    for result in results:\n",
    "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(result)\n",
    "    return output_text\n",
    "\n",
    "@register_keras_serializable()\n",
    "def CTCLoss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom CTC Loss function for sequence prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true (Tensor): True labels.\n",
    "    - y_pred (Tensor): Predicted outputs from the model.\n",
    "    \n",
    "    Returns:\n",
    "    - loss (Tensor): Calculated CTC loss.\n",
    "    \"\"\"\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b79ef4-b505-478b-b190-164066c4f1fa",
   "metadata": {},
   "source": [
    "# Load The Configuration Of Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da8514d3-7160-4890-8656-cd81ade87bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model configuration from JSON\n",
    "with open('./Models/model_config.json', 'r') as json_file:\n",
    "    model_config = json.load(json_file)\n",
    "\n",
    "# Recreate model architecture\n",
    "model = keras.models.model_from_json(json.dumps(model_config))\n",
    "\n",
    "# Load model weights\n",
    "model.load_weights('./Models/Model.h5')\n",
    "\n",
    "# Compile model with custom CTC loss function\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4), loss=CTCLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1064260-d593-4d7e-96d6-02ea451c7a86",
   "metadata": {},
   "source": [
    "# Get prediction using the model and save it in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c10fe6-7293-40a4-8b1d-c7bb8be86b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of test audio files\n",
    "test_files = [os.path.join(test_audio_dir, f) for f in os.listdir(test_audio_dir) if f.endswith('.wav')]\n",
    "\n",
    "# Predict and save to CSV\n",
    "predictions = []\n",
    "for audio_file in test_files:\n",
    "    spectrogram = preprocess_audio(audio_file)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=0)\n",
    "    prediction = model.predict(spectrogram)\n",
    "    decoded_text = decode_batch_predictions(prediction)\n",
    "    predictions.append({'audio': os.path.splitext(os.path.basename(audio_file))[0], 'transcript': decoded_text[0]})\n",
    "\n",
    "# Save predictions to CSV\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Predictions saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
