{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dirization import preprocess_wav, VoiceEncoder\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "(5967, 256)\n"
     ]
    }
   ],
   "source": [
    "#give the file path to your audio file and for the model\n",
    "audio_file_path = './Data/DataForDirization/audio_sample_20.wav'\n",
    "wav_path = Path(audio_file_path)\n",
    "\n",
    "model_file_path = './Models/DIRIZATIONMODEL.pt'\n",
    "model_path= Path(model_file_path)\n",
    "\n",
    "\n",
    "wav = preprocess_wav(wav_path)\n",
    "encoder = VoiceEncoder(\"cpu\", weights_fpath=model_path)\n",
    "_, cont_embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True, rate=16)\n",
    "print(cont_embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    min_clusters: Minimum number of clusters.\n",
    "        Starting Point: 2\n",
    "        Considerations: Set this based on the smallest number of meaningful groups you expect in your data.\n",
    "\n",
    "    max_clusters: Maximum number of clusters.\n",
    "        Starting Point: 3\n",
    "        Considerations: Set this based on the largest number of groups you expect. You can experiment with higher values if you expect more clusters.\n",
    "\n",
    "    stop_eigenvalue: Threshold for considering significant eigenvalues.\n",
    "        Starting Point: 1×10−21×10−2\n",
    "        Considerations: This controls the precision of eigenvalue computation. A lower value might be needed for more precise clustering but could increase computation time.\n",
    "\n",
    "    row_wise_renorm: Whether to perform row-wise normalization on spectral embeddings.\n",
    "        Starting Point: True\n",
    "        Considerations: Normalization can help in some cases, especially when the data has varying scales.\n",
    "\n",
    "    custom_dist: Distance metric for clustering.\n",
    "        Starting Point: \"cosine\"\n",
    "        Considerations: Cosine distance is suitable for high-dimensional data like embeddings. Other options include \"euclidean\" or custom distance functions.\n",
    "\n",
    "    max_iter: Maximum iterations for clustering (e.g., k-means).\n",
    "        Starting Point: 300\n",
    "        Considerations: This is a standard setting, but you can increase it if the clustering algorithm does not converge.\n",
    "\n",
    "    eigengap_type: Method for computing the eigen gap.\n",
    "        Starting Point: EigenGapType.Ratio\n",
    "        Considerations: The ratio method is commonly used, but other methods may be suitable depending on your data.\n",
    "\n",
    "Best Practices\n",
    "\n",
    "    Data Preprocessing: Ensure your data is preprocessed appropriately (e.g., normalization, noise reduction).\n",
    "    Experimentation: Experiment with different values for min_clusters and max_clusters to see how they affect your results.\n",
    "    Validation: Use methods like silhouette scores, Davies-Bouldin index, or domain-specific metrics to validate your clusters.\n",
    "    Parameter Tuning: Use techniques like grid search or random search to find the best hyperparameters.\n",
    "    Visual Inspection: Visualize clusters when possible to inspect the quality of clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clusterer = SpectralClusterer(\n",
    "    min_clusters=None,  # Default\n",
    "    max_clusters=None,  # Default\n",
    "    refinement_options=None,  # Default\n",
    "    autotune=None,  # Default\n",
    "    fallback_options=None,  # Default\n",
    "    laplacian_type=None,  # Default\n",
    "    stop_eigenvalue=1e-2,  # Default\n",
    "    row_wise_renorm=False,  # Default\n",
    "    custom_dist=\"cosine\",  # Default\n",
    "    max_iter=300,  # Default\n",
    "    constraint_options=None,  # Default\n",
    "    eigengap_type=EigenGapType.Ratio,  # Default\n",
    "    max_spectral_size=None,  # Default\n",
    "    affinity_function=utils.compute_affinity_matrix,  # Default\n",
    "    post_eigen_cluster_function=custom_distance_kmeans.run_kmeans  # Default\n",
    ")\n",
    "\n",
    "labels = clusterer.predict(cont_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_clusters:\n",
    "\n",
    "    Type: Optional[int]\n",
    "    Default: None\n",
    "    Description: Minimum number of clusters allowed.\n",
    "\n",
    "max_clusters:\n",
    "\n",
    "    Type: Optional[int]\n",
    "    Default: None\n",
    "    Description: Maximum number of clusters allowed.\n",
    "\n",
    "refinement_options:\n",
    "\n",
    "    Type: Optional[RefinementOptions]\n",
    "    Default: None\n",
    "    Description: Contains refinement arguments for the affinity matrix.\n",
    "    Options: RefinementOptions object.\n",
    "\n",
    "autotune:\n",
    "\n",
    "    Type: Optional[AutoTune]\n",
    "    Default: None\n",
    "    Description: An AutoTune object to automatically search for p_percentile.\n",
    "    Options: AutoTune object.\n",
    "\n",
    "fallback_options:\n",
    "\n",
    "    Type: Optional[FallbackOptions]\n",
    "    Default: None\n",
    "    Description: Indicates when to run fallback clusterer instead of spectral clusterer.\n",
    "    Options: FallbackOptions object.\n",
    "\n",
    "laplacian_type:\n",
    "\n",
    "    Type: Optional[LaplacianType]\n",
    "    Default: None\n",
    "    Description: Type of the Laplacian matrix to use.\n",
    "    Options: Values from the LaplacianType enum (e.g., LaplacianType.Affinity, LaplacianType.GraphCut).\n",
    "\n",
    "stop_eigenvalue:\n",
    "\n",
    "    Type: float\n",
    "    Default: 1e-2\n",
    "    Description: When computing the number of clusters using the EigenGap principle, eigenvalues smaller than this value are not considered.\n",
    "\n",
    "row_wise_renorm:\n",
    "\n",
    "    Type: bool\n",
    "    Default: False\n",
    "    Description: If True, perform row-wise re-normalization on the spectral embeddings.\n",
    "\n",
    "custom_dist:\n",
    "\n",
    "    Type: Union[str, Callable]\n",
    "    Default: \"cosine\"\n",
    "    Description: Custom distance measure for k-means.\n",
    "    Options: \"cosine\", \"euclidean\", \"mahalanobis\", or any other distance functions defined in scipy.spatial.distance.\n",
    "\n",
    "max_iter:\n",
    "\n",
    "    Type: int\n",
    "    Default: 300\n",
    "    Description: Maximum number of iterations for the custom k-means.\n",
    "\n",
    "constraint_options:\n",
    "\n",
    "    Type: Optional[ConstraintOptions]\n",
    "    Default: None\n",
    "    Description: Contains constraint arguments.\n",
    "    Options: ConstraintOptions object.\n",
    "\n",
    "eigengap_type:\n",
    "\n",
    "    Type: EigenGapType\n",
    "    Default: EigenGapType.Ratio\n",
    "    Description: The type of the eigengap computation.\n",
    "    Options: Values from the EigenGapType enum (e.g., EigenGapType.Ratio, EigenGapType.NormalizedGap).\n",
    "\n",
    "max_spectral_size:\n",
    "\n",
    "    Type: Optional[int]\n",
    "    Default: None\n",
    "    Description: Maximum size of input to the spectral clustering algorithm.\n",
    "\n",
    "affinity_function:\n",
    "\n",
    "    Type: Callable\n",
    "    Default: utils.compute_affinity_matrix\n",
    "    Description: Function to compute the affinity matrix from the embeddings.\n",
    "\n",
    "post_eigen_cluster_function:\n",
    "\n",
    "    Type: Callable\n",
    "    Default: custom_distance_kmeans.run_kmeans\n",
    "    Description: Function to cluster the spectral embeddings after the eigenvalue computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectralcluster import SpectralClusterer\n",
    "from spectralcluster.utils import EigenGapType\n",
    "\n",
    "clusterer = SpectralClusterer(\n",
    "    min_clusters=2,\n",
    "    max_clusters=10,\n",
    "    stop_eigenvalue=1e-4,\n",
    "    # row_wise_renorm=True,\n",
    "    custom_dist=\"cosine\",\n",
    "    max_iter=100,\n",
    "    eigengap_type=EigenGapType.Ratio\n",
    ")\n",
    "labels = clusterer.predict(cont_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelling saved to labelling.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# import numpy as np\n",
    "\n",
    "def create_labelling(labels, wav_splits):\n",
    "    \n",
    "    from Dirization import sampling_rate\n",
    "    times = [((s.start + s.stop) / 2) / sampling_rate for s in wav_splits]\n",
    "    labelling = []\n",
    "    start_time = 0\n",
    "\n",
    "    for i, time in enumerate(times):\n",
    "        if i > 0 and labels[i] != labels[i - 1]:\n",
    "            temp = {\n",
    "                \"start\": float(start_time),\n",
    "                \"end\": float(time),\n",
    "                \"speaker\": int(labels[i - 1])\n",
    "            }\n",
    "            labelling.append(temp)\n",
    "            start_time = time\n",
    "        if i == len(times) - 1:\n",
    "            temp = {\n",
    "                \"start\": float(start_time),\n",
    "                \"end\": float(time),\n",
    "                \"speaker\": int(labels[i])\n",
    "            }\n",
    "            labelling.append(temp)\n",
    "\n",
    "    return labelling\n",
    "\n",
    "predicted_data = create_labelling(labels, wav_splits)\n",
    "\n",
    "# Save the labelling to a JSON file\n",
    "with open('./Output/Ourlabelling.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(predicted_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Labelling saved to labelling.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to read JSON file\n",
    "def read_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Read the JSON files\n",
    "reference_path = './Data/DataForDirization/audio_sample_20.json'\n",
    "# file2_path = 'path/to/second_file.json'\n",
    "\n",
    "reference_data = read_json(reference_path)\n",
    "# data2 = read_json(file2_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlap(interval1, interval2):\n",
    "    start = max(interval1['start'], interval2['start'])\n",
    "    end = min(interval1['end'], interval2['end'])\n",
    "    return max(0, end - start)\n",
    "\n",
    "def calculate_diarization_errors(reference, predicted):\n",
    "    FA = 0\n",
    "    Miss = 0\n",
    "    Error = 0\n",
    "    Total = 0\n",
    "\n",
    "    for ref in reference:\n",
    "        ref_interval = {'start': ref['start'], 'end': ref['end']}\n",
    "        Total += ref_interval['end'] - ref_interval['start']\n",
    "        overlap_found = False\n",
    "\n",
    "        for pred in predicted:\n",
    "            pred_interval = {'start': pred['start'], 'end': pred['end']}\n",
    "            overlap = calculate_overlap(ref_interval, pred_interval)\n",
    "\n",
    "            if overlap > 0:\n",
    "                overlap_found = True\n",
    "                if ref['speaker'] != pred['speaker']:\n",
    "                    Error += overlap\n",
    "                # Reduce overlap from predicted interval to avoid double counting\n",
    "                pred['start'] = max(pred['start'], ref['end'])\n",
    "        \n",
    "        if not overlap_found:\n",
    "            Miss += ref_interval['end'] - ref_interval['start']\n",
    "\n",
    "    for pred in predicted:\n",
    "        pred_interval = {'start': pred['start'], 'end': pred['end']}\n",
    "        FA += pred_interval['end'] - pred_interval['start']\n",
    "\n",
    "    DER = (FA + Miss + Error) / Total\n",
    "    return DER, FA, Miss, Error, Total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DER: -0.6898\n",
      "False Alarm (FA): -403.8480\n",
      "Miss: 12.0387\n",
      "Error: 130.7210\n",
      "Total: 378.5250\n"
     ]
    }
   ],
   "source": [
    "# Calculate DER\n",
    "DER, FA, Miss, Error, Total = calculate_diarization_errors(reference_data, predicted_data)\n",
    "\n",
    "# Print the results\n",
    "print(f'DER: {DER:.4f}')\n",
    "print(f'False Alarm (FA): {FA:.4f}')\n",
    "print(f'Miss: {Miss:.4f}')\n",
    "print(f'Error: {Error:.4f}')\n",
    "print(f'Total: {Total:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DER: -0.6611\n",
    "# False Alarm (FA): -393.4836\n",
    "# Miss: 12.0387\n",
    "# Error: 131.2010\n",
    "# Total: 378.5250"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
