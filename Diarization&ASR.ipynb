{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import All Packages That I Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Diarization.AdditionFunctions import create_labelling, SpectralClusterer, EigenGapType \n",
    "from Diarization.audio import Dpreprocess_wav\n",
    "from Diarization.voice_encoder import VoiceEncoder\n",
    "\n",
    "from ASR.AdditionFunctions import load_asr_model, predict_text\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your paths using pathlib\n",
    "\n",
    "audio_folder_path = Path('./Data/DataForDiarization/')\n",
    "modelD_file_path = Path('./Models/DIARIZATIONMODEL.pt')\n",
    "modelA_file_path = Path('./Models/ASRMODEL.weights.h5')\n",
    "modelA_Config_file_path = Path('./Models/ASRMODELCONFIG.json')\n",
    "diarization_folder_path = Path('./Output/DiarizationResults')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dirization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the voice encoder model\n",
    "encoder = VoiceEncoder(\"cpu\", weights_fpath=modelD_file_path)\n",
    "\n",
    "# Configure the spectral clusterer\n",
    "clusterer = SpectralClusterer(\n",
    "    min_clusters=2,\n",
    "    max_clusters=10,\n",
    "    eigengap_type=EigenGapType.Ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each audio file in the folder\n",
    "audio_files = Path(audio_folder_path).glob('*.wav')\n",
    "for audio_file_path in tqdm(audio_files, desc=\"Processing audio files\"):\n",
    "    wav = Dpreprocess_wav(audio_file_path)\n",
    "    _, cont_embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True, rate=16)\n",
    "\n",
    "    labels = clusterer.predict(cont_embeds)\n",
    "    predicted_data = create_labelling(labels, wav_splits)\n",
    "\n",
    "    # Save the labelling to a JSON file with the same name as the audio file\n",
    "    output_file_path = Path(diarization_folder_path) / f\"{audio_file_path.stem}.json\"\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(predicted_data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ASR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASR_model = load_asr_model(modelA_Config_file_path, modelA_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each diarization file in the folder\n",
    "diarization_files = Path(diarization_folder_path).glob('*.json')\n",
    "for diarization_path in tqdm(diarization_files, desc=\"Processing diarization files\"):\n",
    "    # Load the diarization segments\n",
    "    with open(diarization_path, 'r', encoding='utf-8') as file:\n",
    "        diarization_segments = json.load(file)\n",
    "\n",
    "    # Load the corresponding audio file\n",
    "    audio_file_name = diarization_path.stem + '.wav'\n",
    "    audio_path = Path(audio_folder_path) / audio_file_name\n",
    "    audio, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Predict text for each diarization segment with a progress bar\n",
    "    for segment in tqdm(diarization_segments, desc=\"Processing segments\"):\n",
    "        start_sample = int(segment['start'] * sr)\n",
    "        end_sample = int(segment['end'] * sr)\n",
    "        segment_audio = audio[start_sample:end_sample]\n",
    "        text = predict_text(segment_audio, ASR_model)\n",
    "        segment['text'] = text\n",
    "\n",
    "    # Overwrite the existing JSON file with the new predictions\n",
    "    with open(diarization_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(diarization_segments, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks ALL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
